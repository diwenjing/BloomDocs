## SnappyData 介绍
SnappyData将Apache Spark与内存数据库融合，以提供能够在单个集群中处理流，事务和交互式分析的数据引擎。

### Spark和内存数据处理的挑战

Apache Spark是一种用于大规模分析的通用并行计算引擎。它的核心是有一个批量设计中心，可以以高度并行化的方式访问不同的数据源进行分布式计算。通常，由于SQL查询或数据集（RDD）的实现，数据被延迟地提取。如果数据集必须重复处理，这可能是非常低效的。Spark中的缓存是不可变的，仍然需要应用程序来定期刷新数据集，更不用说承担复制数据集的负载。

分析处理需要重复复制大量数据集，并重新格式化数据以适应Spark。在许多情况下，它最终无法实现交互式分析性能的承诺。例如，每次在一个大的Cassandra表上运行聚合时，需要将整个表格串流到Spark中进行聚合。Spark中的缓存是不可变的，导致无法实现实时交互分析。

### SnappyData思路

在SnappyData中，我们采取了非常不同的方法。SnappyData通过共享内存管理和优化，将低延迟，高可用性的内存中事务数据库（GemFireXD）融合到Spark中。高可用性内存存储中的数据使用与Spark相同的柱状格式进行布局。通过更好的向量化和代码生成，所有查询引擎运算符都得到更好的优化。与本机Spark缓存相比，其效果是性能提升了一个数量级，并且在使用外部数据源时性能提高了两个数量级以上。

本质上，我们将Spark转变为能够进行事务，点读取，写入，使用Streams（Spark）和运行分析SQL查询的内存中操作数据库。

在概念上，您可以将SnappyData视为使用Spark的API和SQL作为其接口和计算引擎的内存数据库，以处理流，通过诸如HDFS等各种外部数据源进行处理，并通过丰富的高级抽象来处理数据。虽然SnappyData引擎主要用于SQL处理，但是应用程序可以通过Spark RDD和新引入的Spark Datasets来处理对象。

任何Spark DataFrame可以轻松地作为SnappyData表进行管理，或者相反，任何表都可以作为DataFrame访问。

默认情况下，当集群启动时，数据存储将被引导，并且当提交任何Spark Jobs / OLAP查询时，Spark执行程序将在SnappyData进程空间（JVM）内自动启动。不需要连接和管理外部数据存储集群。SnappyData存储可以同步复制高可用性（HA），具有强大的一致性，并从磁盘存储/恢复以获得更多的可靠性。

### 主要特性

- 与Spark兼容100％ - 使用SnappyData作为数据库，还可以使用任何Spark API --ML，Graph等。
- 内存中的行和列存储：运行存储在Spark执行程序或其自己的进程空间中的存储（即计算集群和数据集群）
- SQL标准合规性：Spark SQL +几个SQL扩展：DML，DDL，索引，约束。
- 用于流处理的基于SQL的扩展：使用本机Spark流，DataFrame API或声明式指定流以及您希望处理的流。在并行处理时，您不需要学习Spark API来处理流处理或其细微之处。
- SQL+ NoSQL：使用SQL数据库或使用JSON或甚至任意的应用程序对象。本质上，任何Spark RDD / DataSet也可以持久保存在SnappyData表（类型系统与Spark DataFrames相同）中。
- 使用概要数据引擎（SDE）的交互式分析：我们通过诸如count-min-sketch和分层抽样之类的数据结构介绍多个概要技术，以显着减少内存空间需求，并为分析查询提供真正的交互式速度。这些结构可以由几乎没有统计学背景的开发人员创建和管理，并且可以对运行查询的SQL开发人员完全透明。错误估计器也与简单的机制集成，通过内置的SQL函数来获取错误。
- 在Spark中对数据进行突变，处理：可以使用SQL在表中插入，更新，删除数据。我们还提供Spark的上下文的扩展，以便您可以在Spark程序中更改数据。SnappyData中的任何表都可视为DataFrames，而无需维护数据的多个副本：在Spark中缓存的RDD，然后在数据存储中单独存储。
- 优化 - 索引：您可以对RowStore和GemFire SQL优化器进行索引，该优化器会在可用时自动使用内存中的索引。
- 优化 - 联位：SnappyData实现了几个优化，以提高数据的局部性，并避免对分区数据集上的查询进行混洗数据。所有相关数据可以使用声明式自定义分区策略进行联位（例如，普通共享业务密钥）。当表不能共享公共密钥时，引用数据表可以被建模为复制表。副本总是一致的。
- 高可用性不仅仅是容错：数据可以立即复制（一次一个或一次一个批处理）到集群中的其他节点。它与基于会员的分布式系统深入集成，以检测和处理故障，即时为HA提供应用程序。
- 耐用性和恢复性：数据也可以在磁盘上进行管理并自动恢复。用于备份和还原的实用程序是捆绑的。


### Spark运行时的扩展

SnappyData提供以下贡献来提供统一和优化的运行时。

- 将运行中的内存数据存储与Spark的计算模型集成在一起：我们引入了一些扩展，将我们的运行时与Spark融合。Spark执行器与我们存储的执行线程相同的进程空间运行，共享相同的内存池。当Spark以分区方式执行任务时，它被设计为全线CPU核心运行。
我们通过允许低延迟和细粒度的操作来交织和获得更高的优先级，而不涉及调度器来扩展此设计。此外，为了支持高并发性，我们用“作业服务器”来延长运行时间，使应用程序与数据服务器分离，与传统数据库的运行方式大致相同，从而在许多客户端和应用程序间共享状态。

- 用于OLAP，OLTP和Streaming的统一API：Spark构建在一组通用抽象上，为各种应用程序（如MapReduce，机器学习，流处理和SQL）提供丰富的API。虽然Spark值得信赖，成为第一个提供统一的API，我们进一步扩展其API到：
  允许OLTP操作，例如表上的事务和更新（插入/更新/删除）
  例如，使用SQL标准进行确认，允许表更改，约束，索引和
  支持SQL中声明式流处理

- 优化Spark应用程序执行时间：我们的目标是消除对Spark应用程序的另一个外部存储（例如KV存储）的需求。通过深度整合数据存储，SnappyData通过最大限度地减少网络流量和序列化成本来提高整体性能。另外，通过在相同的进程空间中并行配置相关数据来促进联位模式设计（表和流），SnappyData在几种情况下不需要完全混洗。

- Spark中内置的简介数据引擎支持：SnappyData概要数据引擎（SDE）提供了一种新颖且可扩展的系统来分析大型数据集。SDE使用统计抽样技术和概率数据结构来回答具有次秒延迟的分析查询。没有必要存储或处理整个数据集。该方法可以快速响应时间查询精度。

### 混合工作负载（OLTP，OLAP）的Spark挑战

Spark被设计为用于处理批处理作业的计算引擎。每个Spark应用程序（例如，Map-reduce作业）作为一组独立的进程（即，执行器JVM）在集群上运行。这些JVM在应用程序的生命周期中被重新使用。虽然数据可以在单个应用程序的这些JVM中缓存和重用，但跨应用程序或客户端共享数据需要外部存储层，如HDFS。另一方面，我们的目标是实时的“永远在线”的运营设计中心 - 客户端可以随意连接，并在任意数量的并发连接中共享数据。这与当今市场上的任何运营数据库类似。因此，为了管理同一个JVM中的数据，我们的第一个挑战是改变这些执行器的生命周期，使其长期存在并与各个应用程序分离。

Spark的另一个但相关的挑战是Spark为用户请求（即作业）的处理设计。一名司机编排了执行人员所做的一切工作。鉴于我们需要高并发性和混合OLTP-OLAP工作负载，该驱动程序介绍：

1.针对所有请求的单一争用点，以及
2.实现高可用性（HA）的障碍。如果驱动程序出现故障，执行程序将关闭，需要完全刷新任何缓存状态。

Spark的主要用途是缓存RDD和将其他节点的混洗块。数据以块为单位进行管理，是不可变的。另一方面，我们需要管理更复杂的数据结构（以及索引）来进行点访问和更新。因此，另一个挑战是将这两个不同的存储系统合并到应用程序的阻抗很小。Spark SQL的当前局限性，主要与可变性特征和SQL的一致性相关，这一挑战更加严重。










































